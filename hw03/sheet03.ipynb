{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa267bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44fca659c1e85aa18c1a44bcb17af98a",
     "grade": false,
     "grade_id": "h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabr√ºck University - Machine Learning (Summer Term 2024) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Lukas Niehaus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950e9e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97519dea34fb4c70583edf24a2480a66",
     "grade": false,
     "grade_id": "cell-e9802371e834eb85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise Sheet 03: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d850d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7444cb0d7448e6dbb896f84ac18f83f9",
     "grade": false,
     "grade_id": "cell-f790e30691d4d590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Sunday, May 5th, 2022**. If you need help (and Google and other resources were not enough), feel free to contact your groups designated tutor or whomever of us you run into first. Please upload your results to your group's studip folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e89a50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3413eef40112c3c4c462c1fd72e6d4e",
     "grade": false,
     "grade_id": "cell-0ceaa7378e4a713d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 0: Math recap (Eigenvectors and Eigenvalues) [0 Points]\n",
    "\n",
    "This exercise does not give any points, and is voluntary. There will be a similar exercise on every sheet. It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them. Eigenvectors and eigenvalues may be less familiar, so this may be a good time to look them up again (you will only need the basic concepts, you do not have to know how to actually compute them for this class). You are always welcome to discuss questions with the tutors or in the practice session. Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b8ec6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "226eb9ff63b2800bb50ff95dec0d1964",
     "grade": false,
     "grade_id": "cell-106b918b6f9c6fea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## a) Eigenvectors and eigenvalues\n",
    "\n",
    "What is an eigenvector of a matrix/a linear mapping? What are eigenvalues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67740d56",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36475d2d0f85070bc2f5c7617633e228",
     "grade": true,
     "grade_id": "cell-f80e2cfbc5dae96a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaae6f4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f18c9c4726e3a12611f49db0a4f8cf9",
     "grade": false,
     "grade_id": "cell-10c6f038150609e1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## b) Characteristic polynomial\n",
    "\n",
    "What is the characteristic polynomial of a matrix? How is it related to eigenvalues? What are algebraic and geometric multiplicity of an eigenvalue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c968ecd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ff3d7e15d56e4dbc54eaef465500577",
     "grade": true,
     "grade_id": "cell-c45db6ae30a5507a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af692712",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e07274f439aa80143fcfa09cbbb2f5a",
     "grade": false,
     "grade_id": "cell-7822385798587c45",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## c) Spectrum\n",
    "\n",
    "What is the spectrum of a matrix? What does the spectral theorem state?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154bdd2c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94696dd22018d912b2a84a73c0a13030",
     "grade": true,
     "grade_id": "cell-1a5e17baf68e02e1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9767072",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5466c6ce52096482e93e5a3959969da1",
     "grade": false,
     "grade_id": "math-eigen-q4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## d) Numpy/Scipy [bonus task]\n",
    "\n",
    "Numpy/Scipy provide functions to compute eigenvalues. Lookup these functions and apply them to an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393683c5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "921f072e460d78509d4e2626c8d1008f",
     "grade": true,
     "grade_id": "cell-2400c166c6ecc90d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf76c3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "061309ba9f2afb8ea384b985dcd298c3",
     "grade": false,
     "grade_id": "pnorm",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Assignment 1: p-norm (6 points)\n",
    "\n",
    "A very well known norm is the euclidean distance. However, it is not the only norm: It is in fact just one of many p-norms where $p = 2$. In this assignment you will take a look at other p-norms and see how they behave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6eaaa0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0568d998dbbdefba97f30b65a8403923",
     "grade": false,
     "grade_id": "2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(a)** Implement a function `pnorm` which expects a vector $x \\in \\mathcal{R}^n$ and a scalar $p \\geq 1, p \\in \\mathcal{R}$ and returns the p-norm of $x$ which is defined as:\n",
    "\n",
    "$$||x||_p = \\left(\\sum\\limits_{i=1}^n |x_i|^p \\right)^{\\frac{1}{p}}$$\n",
    "\n",
    "*Note:* Even though the norm is only defined for $p \\geq 1$, values $0 < p < 1$ are still interesting. In that case we can not talk about a norm anymore, as the triangle inequality ($||a|| + ||b|| \\geq ||a + b||$) does not hold. We will still take a look at some of these values, so your function should handle them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbdb1a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ec229467f9f1c28ffefc15b7d105967",
     "grade": false,
     "grade_id": "2a_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pnorm(x, p):\n",
    "    \"\"\"\n",
    "    Calculates the p-norm of x.\n",
    "    \n",
    "    Args:\n",
    "        x (array): the vector for which the norm is to be computed.\n",
    "        p (float): the p-value (a positive real number).\n",
    "        \n",
    "    Returns:\n",
    "        The p-norm of x.\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    # YOUR CODE HERE\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9cf24",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ce4a51f288ab2f3d6d6511ec64c7a49",
     "grade": true,
     "grade_id": "2a_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Epsilon: Account for rounding erros\n",
    "epsilon = 1e-8\n",
    "assert abs(pnorm(1, 2)      - 1          ) < epsilon, \"pnorm is incorrect for x = 1, p = 2\"\n",
    "assert abs(pnorm(2, 2)      - 2          ) < epsilon, \"pnorm is incorrect for x = 2, p = 2\"\n",
    "assert abs(pnorm([2, 1], 2) - np.sqrt(5) ) < epsilon, \"pnorm is incorrect for x = [2, 1], p = 2\" \n",
    "assert abs(pnorm(2, 0.5)    - 2          ) < epsilon, \"pnorm is incorrect for x = 2, p = 0.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72781d7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3825d4ffce97c1e41d8aac1866a40a2",
     "grade": false,
     "grade_id": "2b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(b)** Implement another function `pdist` which expects two vectors $x_0 \\in \\mathcal{R}^n, x_1 \\in \\mathcal{R}^n$ and a scalar $p \\geq 1, p \\in \\mathcal{R}$ and returns the distance between $x_0$ and $x_1$ on the p-norm defined by $p$. Again handle $0 < p < 1$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae88d2d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50ac04eece9d414f9d3321b9d6b21004",
     "grade": false,
     "grade_id": "2b_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pdist(x0, x1, p):\n",
    "    \"\"\"\n",
    "    Calculates the distance between x0 and x1\n",
    "    using the p-norm.\n",
    "    \n",
    "    Arguments:\n",
    "        x0 (array): the first vector.\n",
    "        x1 (array): the second vector.\n",
    "        p (float): the p-value (a positive real number).\n",
    "        \n",
    "    Returns:\n",
    "        The p-distance between x0 and x1.\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    # YOUR CODE HERE\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6533d3e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7683450657442c62b235085b887882ef",
     "grade": true,
     "grade_id": "2b_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Epsilon: Account for rounding erros\n",
    "epsilon = 1e-8\n",
    "assert abs(pdist(1, 2, 2)           - 1          ) < epsilon , \"pdist is incorrect for x0 = 1, x1 = 2, p = 2\"\n",
    "assert abs(pdist(2, 5, 2)           - 3          ) < epsilon , \"pdist is incorrect for x0 = 2, x1 = 5, p = 2\"\n",
    "assert abs(pdist([2, 1], [1, 2], 2) - np.sqrt(2) ) < epsilon , \"pdist is incorrect for x0 = [2, 1], x1 = [1, 2], p = 2\" \n",
    "assert abs(pdist([2, 1], [0, 0], 2) - np.sqrt(5) ) < epsilon , \"pdist is incorrect for x0 = [2, 1], x1 = [0, 0], p = 2\" \n",
    "assert abs(pdist(2, 0, 0.5)         - 2          ) < epsilon , \"pdist is incorrect for x0 = 2, x1 = 0, p = 0.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c952d95",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41ce9ca1cab536fa959306bfb3a3d2dc",
     "grade": false,
     "grade_id": "2c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**(c)** Now we will compare some different p-norms. Below is part of a code to plot data in nice scatter plots. \n",
    "\n",
    "Your task is to calculate the data to plot. The variable `data` is currently simply filled with zeros. Instead, fill it as follows:\n",
    "\n",
    "- Use the function `np.linspace()` to create a vector of `50` evenly distributed values between `-100` and `100` (inclusively).\n",
    "- Fill `data`: Data is basically the cartesian product of the vector you created before with itself filled up with each value's norm. It should have 2500 rows. Each of the 2500 rows should contain `[x, y, d]`, where `x` is the x coordinate and `y` the y coordinate of a point, and `d` the p-norm of `(x, y)`. Use either `pnorm` or `pdist` to calculate `d`.\n",
    "- Normalize the data in `data[:,2]` (i.e. all d-values) so that they are between 0 and 1.\n",
    "\n",
    "Run your code and take a look at your results. Darker colors mean that a value is further away from the center (0, 0) according to the p-norm used.\n",
    "\n",
    "*Hint:* To give you an idea of how `data` should look like, here is an example for three evenly distributed values between `-1` and `1` and a p-norm with `p = 2`.\n",
    "\n",
    "Before normalization of the d-column:\n",
    "\n",
    "```python\n",
    "data = np.array([[-1.         -1.          1.41421356]\n",
    "                 [-1.          0.          1.        ]\n",
    "                 [-1.          1.          1.41421356]\n",
    "                 [ 0.         -1.          1.        ]\n",
    "                 [ 0.          0.          0.        ]\n",
    "                 [ 0.          1.          1.        ]\n",
    "                 [ 1.         -1.          1.41421356]\n",
    "                 [ 1.          0.          1.        ]\n",
    "                 [ 1.          1.          1.41421356]])\n",
    "```\n",
    "\n",
    "After normalization of the d-column:\n",
    "\n",
    "```python\n",
    "data = np.array([[-1.         -1.          1.        ]\n",
    "                 [-1.          0.          0.70710678]\n",
    "                 [-1.          1.          1.        ]\n",
    "                 [ 0.         -1.          0.70710678]\n",
    "                 [ 0.          0.          0.        ]\n",
    "                 [ 0.          1.          0.70710678]\n",
    "                 [ 1.         -1.          1.        ]\n",
    "                 [ 1.          0.          0.70710678]\n",
    "                 [ 1.          1.          1.        ]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa85511",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4817c66c1673d36bda56d35997ab6bc4",
     "grade": true,
     "grade_id": "3c_code",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ColorConverter\n",
    "\n",
    "color = ColorConverter()\n",
    "figure_norms = plt.figure('p-norm comparison')\n",
    "\n",
    "# create the linspace vector\n",
    "# YOUR CODE HERE\n",
    "\n",
    "assert len(ls) == 50 , 'ls should be of length 50.'\n",
    "assert (min(ls), max(ls)) == (-100, 100) , 'ls should range from -100 to 100, inclusively.'\n",
    "\n",
    "for i, p in enumerate([1/8, 1/4, 1/2, 1, 1.5, 2, 4, 8, 128]):\n",
    "    # Create a numpy array containing useful values instead of zeros.\n",
    "    data = np.zeros((2500, 3))\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    assert data[100,2]>0.9 and data[100,2]<1, \"Wrong result for p norm, make sure you use NORM and not pdist!\"\n",
    "    assert all(data[:,2] <= 1), 'The third column should be normalized.'\n",
    "\n",
    "    # Plot the data.\n",
    "    colors = [color.to_rgb((1, 1-a, 1-a)) for a in data[:,2]]\n",
    "    a = plt.subplot(3, 3, i + 1)\n",
    "    plt.scatter(data[:,0], data[:,1], marker='.', color=colors)\n",
    "    a.set_ylim([-100, 100])\n",
    "    a.set_xlim([-100, 100])\n",
    "    a.set_title('{:.3g}-norm'.format(p))\n",
    "    a.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    figure_norms.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ef9ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99197aee3844f7ab62df7fb26c8a4da7",
     "grade": false,
     "grade_id": "pnorm-d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(d)** In the first parts of this exercise we have used the fact that every $p$-norm induces an associated metric by setting $d_p(x,y):=\\|x-y\\|_p$ for $x,y\\in\\mathcal{R}^{n}$.  Show that for $p\\ge 1$ this function $d_p$ indeed fulfills the conditions listed on ML-04 slide 39. What problems occur for $p<1$?\n",
    "\n",
    "Hint: start with a specific case, e.g. the Euclidean metric $p=2$ for a low dimension $n$ and then generalize your arguments to other values of $n$ and $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd3e96",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "196e050a3a695f92fd22dc3a0dd69867",
     "grade": true,
     "grade_id": "p-norm-d-answer",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb88c72",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f70f61b9f9e53bdf15807c7e43d2e4eb",
     "grade": false,
     "grade_id": "1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 2: Distance Measures for Clusters (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc2430",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed9588bc5f01406fd69f8a4822c5d38f",
     "grade": false,
     "grade_id": "1_ax",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## a) Point and cluster distances\n",
    "\n",
    "Explain the difference of point and cluster distances and their relation to each other. Give examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2198dc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "284368872533018ef80860f1fe589eae",
     "grade": true,
     "grade_id": "cell-64b9b3273be847ac",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7929389",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b82a28881dcef0fbc9519d8aa3ac581a",
     "grade": false,
     "grade_id": "cell-efa27e859e56e6dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## b) Mean and centroid distance\n",
    "\n",
    "* Describe how the cluster metrics *mean distance* and *centroid distance* work.\n",
    "* What formal requirements do they have?\n",
    "* What is their computational complexity (use the [Big O notation](https://en.wikipedia.org/wiki/Big_O_notation))? \n",
    "* Give a numerical example of clusters (with cluster size at least 2), where they lead to (a) the same result and (b) different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b41d9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c2d641c8c6d68d1b72a02b5f3236393",
     "grade": true,
     "grade_id": "cell-d8619b5b4e63d573",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885fce0e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2eeeb4bd540b19f40b28bbda5428ed80",
     "grade": false,
     "grade_id": "1_b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## c) Implemention of  mean and centroid distance\n",
    "\n",
    "Now implement the $d_{mean}$ and $d_{centroid}$ distance from the lecture. Each function expects two clusters each represented by a 2-dimensional numpy array, where the number of columns $n$ reflects the dimensionality of the data space and has to agree for both clusters, while the number of rows $mx$ and $my$ can vary from cluster to cluster. The return value is the respective distance.  Use the Euclidean distance as underlying metric.\n",
    "\n",
    "Hint: you may consider using the function `scipy.spatial.distance.cdist`. Consult the documentation to find out how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9705ec",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6461d8332fc7d2d2cadea2aea316f6a8",
     "grade": true,
     "grade_id": "1_b_code",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "def d_mean(cluster1, cluster2):\n",
    "    \"\"\"\n",
    "    Mean distance between points of two clusters.\n",
    "   \n",
    "    Args:\n",
    "        cluster1 (ndarray): Points belonging to cluster 1 of shape (num_points, num_dimensions).\n",
    "        cluster2 (ndarray): Points belonging to cluster 1 of shape (num_points, num_dimensions).\n",
    "    \n",
    "    Returns:\n",
    "        float: The mean distance between the points in the two clusters.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "x = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "y = np.array([[13,14,15], [16,17,18], [19,20,21], [5,45,1], [1,12,7]])\n",
    "\n",
    "epsilon = 1e-3\n",
    "assert abs(d_mean(x, y) - 22.297) < epsilon, \"Result is not correct: {}\".format(d_mean(x, y))\n",
    "assert d_mean(x, y) == d_mean(y, x), \"X,Y is not equal to Y,X: {} != {}\".format(d_mean(x, y), d_mean(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65075ae2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "401f4da23fe87df2d3b78bbd599f2e68",
     "grade": true,
     "grade_id": "1_c_code",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def d_centroid(cluster1, cluster2):\n",
    "    \"\"\"\n",
    "    Calculate the distance between the centroids of two clusters.\n",
    "    \n",
    "    Args:\n",
    "        cluster1 (ndarray): Points belonging to cluster 1 of shape (num_points, num_dimensions).\n",
    "        cluster2 (ndarray): Points belonging to cluster 1 of shape (num_points, num_dimensions).\n",
    "    \n",
    "    Returns:\n",
    "        float: The distance between the centroids of two clusters.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "\n",
    "x = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "y = np.array([[13,14,15], [16,17,18], [19,20,21]])\n",
    "z = np.array([[-2,0], [-1,100]])\n",
    "w = np.array([[2,0], [1,100], [1,-100], [1,-20]])\n",
    "\n",
    "epsilon = 1e-3\n",
    "assert abs(d_centroid(x, y) - 20.785) < epsilon, \"Result is not correct: {}\".format(d_centroid(x, y))\n",
    "assert abs(d_centroid(z, w) - 55.069) < epsilon, \"Result is not correct: {}\".format(d_centroid(z, w))\n",
    "assert d_centroid(x, y) == d_centroid(y, x), \"X,Y is not equal to Y,X: {} != {}\".format(d_centroid(x, y), d_centroid(y, x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7910ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe1ed21618566e2df07e0192a73749b8",
     "grade": false,
     "grade_id": "cell-1aa3a155692767cb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " # Assignment 3: Hierarchical Clustering (5 points)\n",
    " \n",
    " Consider the following matrix of distances\n",
    " \n",
    "|       |  a  |  b  |  c  |  d  |  e  |\n",
    "|-------|-----|-----|-----|-----|-----|\n",
    "| **a** |  0  |  2  |  6  |  10 |  9  |\n",
    "| **b** |  2  |  0  |  5  |  9  |  8  |\n",
    "| **c** |  6  |  5  |  0  |  4  |  5  |\n",
    "| **d** |  10 |  9  |  4  |  0  |  3  |\n",
    "| **e** |  9  |  8  |  5  |  3  |  0  |\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc2346d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbf5627828ca73eb65653f3087306747",
     "grade": false,
     "grade_id": "cell-178fda94686d02f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## a) Perform agglomerative clustering\n",
    "\n",
    "Do *agglomerative* average linkage clustering by hand (i.e. employing the *mean* cluster distance). Analyze how many alternatives you have to consider at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd090b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afe395ecdd2062d73e972ceea170b3ab",
     "grade": true,
     "grade_id": "cell-1b175c45344ce687",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71d786",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1873f92963a4a8a4c8d87f8533c274e0",
     "grade": false,
     "grade_id": "cell-f0e512db6f3b50fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## b) Perform divisive clustering\n",
    "\n",
    "Now try to do divisive average linkage clustering. Again, analyze how many splits are possible in the first step? Think of a strategy that allows to reduce this number and use this in your computation. Then apply the strategy to obtain a hierarchical clustring, that is iteratively split clusters until all clusters are singletons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611bc13b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7286b998d401450f564417c936e298e",
     "grade": true,
     "grade_id": "cell-273971298318f089",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038bece",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dbdf2fb882d1598aed20af97a9c6a72",
     "grade": false,
     "grade_id": "2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## c) Linkage criteria\n",
    "\n",
    "In the following you find implementations for single- and complete-linkage clustering. Take a look at the code  and answer the question posted below. You may of course change parameters and try it out on different datasets (`points.txt` & `clusterData.txt` are provided).\n",
    "\n",
    "Note that for performance reasons the code differs from the lecture's pseudocode (ML-05 Slide 8), but in general it does the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29234b53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce49d04d93e1ee39db4228e9695bd932",
     "grade": false,
     "grade_id": "cell-bece3476fa1da0d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def linkage(data, k=5, complete=False):\n",
    "    \"\"\"\n",
    "    Runs single or complete linkage clustering.\n",
    "    \n",
    "    Args:\n",
    "        data (ndarray): Data points to be clustered in an array with shape (num_points, 2).\n",
    "        k (int): Number of clusters.\n",
    "        complete (bool): Whether to run complete linkage clustering.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: The cluster labels for each data point. Shape is (num_points).\n",
    "    \"\"\"\n",
    "    # Initially all points are their own cluster.\n",
    "    labels = np.arange(len(data))\n",
    "\n",
    "    # Calculate distance between all points.\n",
    "    # Also removing half of the matrix because \n",
    "    # its symmetrical along the diagonal.\n",
    "    dst = np.tril(cdist(data, data))\n",
    "\n",
    "    while len(set(labels)) > k:\n",
    "        # Get the lowest distance of two points which\n",
    "        # do not have the same label.\n",
    "        r, c = np.where(dst == np.min(dst[dst > 0]))\n",
    "        \n",
    "        # Ignore the case when there are multiple with\n",
    "        # equally smallest distance.\n",
    "        r = r[0]\n",
    "        c = c[0]\n",
    "\n",
    "        # The two points are now in the same cluster,\n",
    "        # so they have a distance of 0 now.\n",
    "        dst[r, c] = 0\n",
    "\n",
    "        # Make the two clusters have the same label.\n",
    "        labels[labels == labels[r]] = labels[c]\n",
    "\n",
    "        # Check if we want to do complete linkage clustering.\n",
    "        if complete:\n",
    "            # Update the distances of the points which are not in the same cluster.\n",
    "            for i in np.nonzero(dst[r, :] > 0)[0]:\n",
    "                dst[r, i] = np.max(cdist(data[i, None], data[labels == labels[r], :]))\n",
    "\n",
    "            # The distances to c are now the same as to r, so we can just\n",
    "            # set them to zero - would be duplicates otherwise.\n",
    "            dst[:, c] = 0\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf682a8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a5ab8fb7f662421762d6c4039e035f0",
     "grade": true,
     "grade_id": "cell-88337d69614d2e22",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data.\n",
    "data = np.loadtxt('points.txt')\n",
    "\n",
    "# Show unprocessed data set.\n",
    "fig_cluster = plt.figure()\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "plt.title('Unprocessed Cluster Data')\n",
    "fig_cluster.canvas.draw()\n",
    "\n",
    "# Apply Single Linkage Clustering\n",
    "labels = linkage(data, k=5, complete=False)\n",
    "unique, inverse, counts = np.unique(labels, return_inverse=True, return_counts=True)\n",
    "print(\"Single Linkage Clustering:\")\n",
    "# Print the unqiue labels and their occurence\n",
    "for u, c in zip(unique, counts):\n",
    "    print(\"Label: {:4},  Occurence: {:4}\".format(u, c))    \n",
    "# Replace labels by continuous values starting from 1 for discernible colors in plot\n",
    "labels = np.arange(1,unique.size+1)[inverse]\n",
    "fig_single = plt.figure()\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels)\n",
    "plt.title('Single-linkage Clustering with k=5')\n",
    "fig_single.canvas.draw()\n",
    "\n",
    "\n",
    "# Apply Complete Linkage Clustering\n",
    "labels = linkage(data, k=5, complete=True)\n",
    "unique, inverse, counts = np.unique(labels, return_inverse=True, return_counts=True)\n",
    "print(\"Complete Linkage Clustering:\")\n",
    "for u, c in zip(unique, counts):\n",
    "    print(\"Label: {:4},  Occurence: {:4}\".format(u, c))    \n",
    "labels = np.arange(1,unique.size+1)[inverse]\n",
    "fig_complete = plt.figure()\n",
    "plt.scatter(data[:, 0], data[:, 1], c=labels)\n",
    "plt.title('Complete-linkage Clustering with k=5')\n",
    "fig_complete.canvas.draw()\n",
    "\n",
    "# Test different parameters above\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff820d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44235bcbef2dfbd67299026aa67784f0",
     "grade": false,
     "grade_id": "2_question",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What is the difference between single- and complete-linkage clustering and which is the better solution given the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a38075",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42148b169d77d5c2b5a40dab20fbe0bf",
     "grade": true,
     "grade_id": "2_answer",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
