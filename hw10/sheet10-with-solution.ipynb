{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e2b7a0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabr√ºck University - Machine Learning (Summer Term 2024) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Lukas Niehaus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c63f65",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "h01",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce5192",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "h02",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before end of **Sunday, June 23rd, 2024**. If you need help (and Google and other resources were not enough), feel free to ask in the StudIP forum, contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder.\n",
    "\n",
    "**NOTE:** There will be 11 sheets in total. If you have passed the first nine sheets successfully, you are not obliged to submit this sheet. However we highly recommend to have at least a look at it, as the content may still be relevant for the exam. You may also meet with your tutor to discuss the sheet.  In any case, if you do not intend to meet with your tutor, **please inform them in advance** to allow them to adapt their plans!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd8d16",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78e418c8c7c6b9cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 0: Math recap (Conditional Probability) [0 Points]\n",
    "\n",
    "This exercise is supposed to be easy and is voluntary. There will be a similar exercise on every sheet. It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them. Usually you should have no problem to answer these questions offhand, but if you feel unsure, this is a good time to look them up again. You are always welcome to discuss questions with the tutors or in the practice session. Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e041956",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "math-cprob-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Explain the idea of conditional probability. How is it defined?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df620959",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "math-cprob-a1",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Conditional probability is the probability that an event A happens, given that another event B happened.\n",
    "For example:\n",
    "The probability of rain is $$P(weather=\"rain\") = 0.3$$ But if you observe, if the street is wet you would get the conditional probability $$P(weather= \"rain\" |~ street=\"wet\") = 0.95$$\n",
    "The definition is:\n",
    "$$ P(A|B) = \\frac{P(A,B)}{P(B)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6727f78",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "math-cprob-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is Bayes' theorem? What are its applications?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c28e7a9",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "math-cprob-a2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Bayes Theorem states:\n",
    "$$ P(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)} $$\n",
    "\n",
    "The most important application is in reasoning backwards from event to cause (from data to parameters of your distribution):\n",
    "\n",
    "$$ P(\\Theta|Data) = \\frac{P(Data|\\Theta)P(\\Theta)}{P(Data)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec8de8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "math-cprob-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** What does the law of total probability state? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d0da4",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "math-cprob-a3",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The law of total probability states, that the probabilty of an event occuring is the same as the sum of the probabilities of this event occuring together with all possible states of an other event:\n",
    "$$P(A) = \\sum_b P(A,B=b) = \\sum_b P(A|B=b) P(B=b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68a474",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex-nn2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1: Nearest Neighbor Application (5 points)\n",
    "\n",
    "In this exercise, you will explore the [nearest neighbor implementation](https://scikit-learn.org/stable/modules/neighbors.html) module and some additional functions provided by scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce37632",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex-nn2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Classifying the iris dataset [1 point]\n",
    "\n",
    "In the first part of this exercise you will work on the famous Iris dataset (you should already know it). In the following cell we prepare the dataset for you: the data set is split into two parts: `(X_train, y_train)` contains the training data and `(X_test, y_test)` contain test data for evaluation (part b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd7eb2",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-992234c35cdf502d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now use the prepared data to train a [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Try to create a simple nearest neighbor classifier similar to that used in the lecture ($k=1$, Euclidean metric, no fancy search strategy). Consult the documentation to make sure you understand the different parameters you can pass to this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8b5b7",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e452ca6dd7036b85",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "## BEGIN SOLUTION\n",
    "knn_iris = KNeighborsClassifier(n_neighbors=1, metric='euclidean', algorithm='brute')\n",
    "knn_iris.fit(X_train, y_train)\n",
    "## END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75464601",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6445fefe332bad97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### b) Evaluation of the nearest neighbor classifier [2 points]\n",
    "\n",
    "Explain in the following text cell, how you can assess the performance of your classifier? You may lookup central ideas, like train/test-split and the accuracy score, in the scikit learn documentation. Then evaluate your nearest neighbor classifier in the code cell below (you may use the function [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)). Can you improve the performance by changing parameters of the nearest neighbor classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75b0e8",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7b136e00706eb05d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f92363",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-bbda9aeca278a0c9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "y_pred = knn_iris.predict(X_test)\n",
    "print(f\"Classifier accuracy is {accuracy_score(y_test, y_pred)}\")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e25df",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1ad6511222e3e25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### c) MNIST classification [2 points]\n",
    "\n",
    "In this last part of the exercise we use a new dataset: The MNIST database of handwritten numbers. MNIST consists of 70.0000 handwritten digits, 7.000 for each of the classes 0 to 9. It is nowadays used as a demo dataset, as it is no longer a real challenge for state-of-the-art machine learning algorithms (reaching up to 99.9% accuracy). Still it has many interesting features and can help to compare and study different algorithms. In the following cell, we load the dataset for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34517a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# do not use full dataset (to keep runtime low)\n",
    "train_samples = 5000\n",
    "test_samples = 1000\n",
    "\n",
    "# Download data from https://www.openml.org/d/554 (needs some time ...)\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=train_samples, test_size=test_samples)\n",
    "\n",
    "def random_sample(X, size=None):\n",
    "    \"\"\"Obtain a sample of given size from the dataset `X`.\n",
    "    \"\"\"\n",
    "    return X[np.random.choice(X.shape[0], size=size)]\n",
    "\n",
    "def show_sample(*args, titles=None):\n",
    "    \"\"\"Display one or multiple MNIST samples, with optional `titles`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(4*len(args), 4))\n",
    "    plt.gray()\n",
    "    for i, X in enumerate(args):\n",
    "        plt.subplot(1, len(args), i+1)\n",
    "        plt.imshow(X.reshape(28,28))\n",
    "        if titles is not None:\n",
    "            plt.title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see some random examples from the dataset\n",
    "show_sample(*random_sample(X_test, size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ec1ae",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bcc771453168dc12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now it's your task: train a nearest neighbor classifier on the MNIST dataset. Visualize the k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a48316",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1a78fbf4235d2b2e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# train the classifier\n",
    "knn_mnist = KNeighborsClassifier(n_neighbors=1, algorithm='ball_tree')\n",
    "knn_mnist.fit(X_train, y_train)\n",
    "\n",
    "# select an example from the test set ...\n",
    "X = random_sample(X_test, size=1)\n",
    "\n",
    "# ... obtain the nearest neighbors ...\n",
    "distances, indices = knn_mnist.kneighbors(X)\n",
    "\n",
    "# ... and plot them:\n",
    "show_sample(X[0], *X_train[indices[0]],\n",
    "            titles=['X'] + [f'index {i}: {d:.2f}' for i,d in zip(indices[0],distances[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11156c2e",
   "metadata": {},
   "source": [
    "Experiment with different parameters. What distance measure would you choose for this dataset? What other parameters could you adapt? What accuracy can you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844999f",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9524236c5022500c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = knn_mnist.predict(X_test)\n",
    "print(f\"Classifier accuracy is {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778ed04",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 2: Self-Organizing Maps Theory (4 points)\n",
    "\n",
    "This exercise will highlight the theoretical differences of Self-Organizing Maps (SOMs) to other algorithms we already took a look at. There is again some research involved if the answers are not directly clear from the slides (or even better: your own ideas!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06b517",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex1a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Learning in SOMs: How is learning in such a network achieved? Contrast this with techniques used in training a MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2df58",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1a_sol",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "In self-organizing maps the nodes take part in competitive learning. They compete for each input and a winner is dertermined. The  weights of the winner (and the weights of its neighbors) are the only weights that are adapted. MLPs use error correction learning where a delta of the output to a target value is computed and used to adapt all weights in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be6db9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** Initialization: Usually weights in a SOM are initialized randomly - what would be an alternative?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7b385",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1b_sol",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The nodes/weights can be sampled from the subspace spanned by the largest principal components. With this method learning should become faster since the nodes already have a good initial fit to the structure of the data. This method only works if the dataset is not essentially non-linear, in such a case the random initialization works better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac3023",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex1c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<a id=\"ex1c\"></a>\n",
    "**c)** Decaying learning rate: When training a self organizing map (and also other complex models), it is recommended to use a decaying learning rate. Explain, how this affects the learning process and why it may be beneficial.\n",
    "\n",
    "The following function is often used for this purpose (where $s$ is the current training step and $S$ is the total number of steps to run):\n",
    "\n",
    "$$\\alpha(s, S) = 0.1 \\exp\\left(-\\frac{s}{S-s}\\right)$$\n",
    "\n",
    "Plot its graph and discuss its properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100dcb0a",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1c_sol1",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "A decaying learning rate helps to adapt to the progress during learning: a large learning rate means that the parameters (i.e., the weights) are changed a lot, while a small learning rate will result in only small changes in each iteration. In general, a learning rate that is too high can cause the whole process to fail (the steps are too large to hit the actual minimum), and the system does not converge. On the other hand, a learning rate that is too small will cause the learning process to be very slow, i.e., it needs will need a large number of iterations before reaching the actual minimum.\n",
    "\n",
    "A decaying learning rate is a good compromise, that will take larger steps in the beginning, to quickly bring the initial (random) parameters to a meaningful arrangement that is then finetuned when the learning rate decays. The proposed function starts with a high value, that is (roughly) linearly decreased until reaching a minimum at approximately 80% of the iterations, after which the decay is slowed down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f20292",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1c_sol2",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha = lambda s, S: 0.1 * np.exp(-s / (S - s))\n",
    "\n",
    "S = 1000\n",
    "s = np.arange(S)\n",
    "\n",
    "plt.figure(\"Decaying learning rate\")\n",
    "plt.plot(s, alpha(s, S), '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67333142",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex1d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<a id=\"ex1d\"></a>\n",
    "**d)** Decaying neighborhood function: SOMs use a decaying neighborhood function. Explain its role in the training process.\n",
    "\n",
    "One possible formula for for such a function is the following: let $u$ denote the coordinates of the best matching node, and $v$ the coordinates of some arbitrary node, $n$ the maximum number of nodes in one direction, and let a $s$ and $S$ again be the current step and the total number of steps, respectively: \n",
    "\n",
    "\\begin{align*}\n",
    "  r &= n \\exp\\left( -\\frac{s \\log(n)}{S} \\right) \\\\\n",
    "  \\theta(u, v, s, S) &= \\exp\\left(-\\frac{||u - v||^2}{2r^2}\\right)\n",
    "\\end{align*}\n",
    "\n",
    "Plot its 3D graph for a fixed node $u$ and describe its properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91971b",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1d_sol1",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The neighborhood function determines how strong the winning unit will also update its neighbor. Usually, in the beginning of the training, when the map is not yet organized, each update should pull a large neighborhood into the direction of the winning unit. Later during training, when things are settled, an update step should only influence a small number of weights.\n",
    "\n",
    "The given formulae achieve exactly this: while in the beginning (for small $s$), the $r$ value is large, causing a large neighborhood around the winner $u$ to be updated. When $s$ grows, the neighborhood shrinks and neurons with some distance to $u$ will receive nearly no update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "\n",
    "# The reference point u\n",
    "u = (4, 4)\n",
    "\n",
    "# The total number of steps\n",
    "S = 100\n",
    "\n",
    "# The size of the map (n*n)\n",
    "n = 10\n",
    "\n",
    "# the r function\n",
    "r = lambda n, s, S: n * np.exp(-s * np.log(n) / S)\n",
    "\n",
    "# the theta function\n",
    "theta = lambda u, v, s, S: np.exp(-((u - v)**2).sum(axis=2) / (2 * r(n, s, S)**2))\n",
    "\n",
    "v = np.indices((n, n)).transpose((1, 2, 0))\n",
    "s_range = np.arange(S)\n",
    "\n",
    "fig = plt.figure(\"The theta(u,v,s,S)\", figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "\n",
    "for s in s_range:\n",
    "    ax1.cla()\n",
    "    ax1.set_title(\"r(s) for s={}\".format(s))\n",
    "    ax1.plot(s_range, r(n, s_range, S), '-')\n",
    "    ax1.plot(s, r(n, s, S), '*')\n",
    "\n",
    "    ax2.cla()\n",
    "    ax2.set_title(\"theta(s) for s={}\".format(s))\n",
    "    ax2.set_zlim3d(0, 1)\n",
    "    ax2.plot([u[0]], [u[1]], zs=[0], marker='o', color='orange', markersize=5)\n",
    "    ax2.plot_wireframe(v[:, :, 0], v[:, :, 1], theta(u, v, s, S))\n",
    "\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14441d39",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex2_h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 3: Self-Organizing Maps (7 points)\n",
    "\n",
    "In this exercise you will implement a self-organizing map and use it for a beautiful application: Coloring countries with similar statistics in similar colors. \n",
    "\n",
    "### Additional Information about the Data\n",
    "\n",
    "The data is taken from the [World Bank's World DataBank](http://databank.worldbank.org/data/home.aspx) and preprocessed. Since their data is very sparse we just tried to use the latest possible data for each country in each category. This means there can be data from the 1960 but also from 2015 - for the exercise this shouldn't matter too much. Note that some countries don't have data at all.\n",
    "\n",
    "The [blank map](https://en.wikipedia.org/wiki/File:BlankMap-World6-Equirectangular.svg) is taken from wikipedia. It is an [SVG](https://en.wikipedia.org/wiki/Scalable_Vector_Graphics) file which suits this task well: We can easily display it in Jupyter Notebooks and it is very easy to color them, as this just involves a modification of their style sheet. You can find the code to do this below, you just have to figure out how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ad6f7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex2_h01",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Coloring the Map\n",
    "\n",
    "The following cell defines a method to create a colored version of the empty map and shows an example usage of it.\n",
    "\n",
    "As you can see, the mapping parameter is a dictionary mapping lowercase [ISO 3166-2](https://en.wikipedia.org/wiki/ISO_3166-2) country codes to `[R, G, B]` values which range from `0` to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a512231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display_svg\n",
    "from xml.etree import cElementTree as ET\n",
    "import time\n",
    "\n",
    "def create_colored_map(color_mapping, scaling=0.7, display=True):\n",
    "    \"\"\"\n",
    "    Takes a color mapping to create a world map with the specified \n",
    "    colors.\n",
    "    For example:\n",
    "    \n",
    "    mapping = {'de': [1, 0, 0],\n",
    "               'fr': [0, 1, 0]}\n",
    "    create_and_display_colored_map(mapping)\n",
    "    \n",
    "    will create a worldmap and display it with Germany ('de') \n",
    "    colored red and France ('fr') colored green.\n",
    "    Colors need to be iterables containing R G B values ranging\n",
    "    from 0 (dark) to 1 (bright).\n",
    "    \n",
    "    The template used for the map can be found here:\n",
    "    https://en.wikipedia.org/wiki/File:BlankMap-World6-Equirectangular.svg\n",
    "    \n",
    "    Args:\n",
    "        mapping     A color mapping between country codes and colors.\n",
    "        scaling     Scales the map by this factor. \n",
    "        display     If True, the image is displayed, if False, it is\n",
    "                    returned.\n",
    "    Returns:\n",
    "        The svg image if display=False. Else nothing.\n",
    "    \"\"\"\n",
    "    def color_css(color_mapping, map_id):\n",
    "        \"\"\"Creates a CSS string for the color mapping.\"\"\"\n",
    "        tmpl = '#{4} .{0} {{fill: #{1:0>2x}{2:0>2x}{3:0>2x} !important;}}'\n",
    "        scale = lambda x : [int(255 * i) for i in x]\n",
    "        return '\\n' + '\\n'.join([tmpl.format(country.lower(), *scale(color), map_id) for country, color in color_mapping.items()])\n",
    "\n",
    "    # Read SVG file and get document root.\n",
    "    tree = ET.parse('map.svg')\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Adjust the ID (Otherwise coloring will be global for all SVG images).\n",
    "    time.sleep(1)\n",
    "    root.attrib['id'] = \"{}{}\".format(root.attrib['id'], str(time.time())[0:10])\n",
    "    \n",
    "    # Search the style element and append the color mapping.\n",
    "    style_element = tree.find('{http://www.w3.org/2000/svg}style')\n",
    "    style_element.text = style_element.text + color_css(color_mapping, root.attrib['id'])\n",
    "\n",
    "    # Adjust the image scale.\n",
    "    root.attrib['height'] = str(float(root.attrib['height']) * scaling)\n",
    "    root.attrib['width'] = str(float(root.attrib['width']) * scaling)\n",
    "    \n",
    "    # Create an SVG instance which can be displayed by Jupyter.\n",
    "    svg = SVG(data=ET.tostring(root).decode('UTF-8').replace('ns0:',''))\n",
    "    if display:\n",
    "        display_svg(svg)\n",
    "    else:\n",
    "        return svg\n",
    "\n",
    "# Example for coloring the map.\n",
    "mapping = {'de': [1, 0, 0], \n",
    "           'fr': [0, 1, 0], \n",
    "           'us': [0, 0, 1]}\n",
    "create_colored_map(mapping, scaling=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166e260c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Implement a Self-Organizing Map.\n",
    "\n",
    "Below is a class definition for a self-organizing map. The initialization is already provided. Follow the instruction below to finish it.\n",
    "\n",
    "1. Write a method `get_best_matching_index(self, X)` which returns the indices of the node with the weights closest to `X`. Use the `cdist` function to calculate the distances between `X` and all nodes. *Note:* You might need `unravel_index`.\n",
    "\n",
    "1. Write a method `alpha(self, step, max_steps)` which defines the decaying learning rate. Use the formula from [exercise 1c)](#ex1c), i.e.\n",
    "$$\\alpha(s, S) = 0.1 \\exp\\left(-\\frac{s}{S-s}\\right)$$\n",
    "\n",
    "1. Write a method `theta(self, u, v, step, max_steps)` which defines the decaying neighborhood function. Use the formula from [exercise 1d)](#ex1d), i.e,\n",
    "$$\\theta(u, v, s, S) = \\exp\\left(-\\frac{||u - v||^2}{2r^2}\\right)\\qquad\\text{with }\n",
    "  r = n \\exp\\left( -\\frac{s \\log(n)}{S} \\right) $$\n",
    "\n",
    "1. Write a function `organize(self, max_steps)` which trains the map for `max_steps` steps. Pick a random data sample $X$, calculate the best matching indices $u$ and update each node $v_i$ (with $w_{v_i}$ being the corresponding weight vector) according to the following formula ($s$, $S$, $\\theta$ and $\\alpha$ are as above): \n",
    "$$\\Delta w_{v_i} = \\theta(u, v_i, s, S)\\ (X - w_{v_i})\\ \\alpha(s, S)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f6a10",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex2a_sol",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "class SelfOrganizingMap:\n",
    "    \"\"\"Implements a self-organizing map.\"\"\"\n",
    "\n",
    "    def __init__(self, data, map_size=(20, 20), method='distance'):\n",
    "        \"\"\"\n",
    "        Creates a grid self.nodes of map_size[0] x map_size[1] \n",
    "        many nodes with random weights for each dimension in the \n",
    "        data. This means self.nodes.shape will be \n",
    "        (map_size[0], map_size[1], data.shape[-1]).\n",
    "        \n",
    "        Stores the data in self.data.\n",
    "        \n",
    "        Args:\n",
    "            data        The data to fit with this map.\n",
    "            map_size    The size of the map. Defaults to 20x20.\n",
    "            method      The activation method. Supports 'distance' and 'activation'.\n",
    "        \"\"\"\n",
    "        self.nodes = np.random.rand(map_size[0], map_size[1], data.shape[-1])\n",
    "        self.data = data\n",
    "        self.method = method\n",
    "\n",
    "    def theta(self, u, v, step, max_steps):\n",
    "        \"\"\"\n",
    "        The neighborhood function. \n",
    "        \n",
    "        Args:\n",
    "            u           The best matching node's grid coordinates.\n",
    "            v           Grid coordinates of the (possible) neighboring node.\n",
    "            step        The current step.\n",
    "            max_steps   The maximum number of steps.\n",
    "        \n",
    "        Returns:\n",
    "            A weight of how strong the neighborhood relation between\n",
    "            u and v is at step of max_steps.\n",
    "        \"\"\"\n",
    "        ### BEGIN SOLUTION\n",
    "        max_shape = max(self.nodes.shape[:2])\n",
    "        r = max_shape * np.exp(-(step * np.log(max_shape)) / max_steps)\n",
    "        return np.exp(-np.linalg.norm(u - v)**2 / (2 * r**2))\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def alpha(self, step, max_steps):\n",
    "        \"\"\"\n",
    "        The learning rate. Decays with step.\n",
    "        \n",
    "        Args:\n",
    "            step        The current step.\n",
    "            max_steps   The maximum number of steps.\n",
    "        \"\"\"\n",
    "        ### BEGIN SOLUTION\n",
    "        return 0.1 * np.exp(-step / (max_steps - step))\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def organize(self, max_steps):\n",
    "        \"\"\"\n",
    "        For steps this method organizes the map with its data.\n",
    "        \n",
    "        In each step it picks a random sample from the data and\n",
    "        calculates the best matching node.\n",
    "        The best matching node's indices are calculated with \n",
    "        get_best_matching_index.\n",
    "        Using the indices of that node, all nodes are\n",
    "        updated by applying alpha and theta.\n",
    "        \n",
    "        Args:\n",
    "            max_steps   The number of steps.\n",
    "        \"\"\"\n",
    "        ### BEGIN SOLUTION\n",
    "        for step in range(max_steps):\n",
    "            X = self.data[np.random.randint(0, len(self.data))]\n",
    "            best_match = self.get_best_matching_index(X)\n",
    "\n",
    "            for row_idx in range(self.nodes.shape[0]):\n",
    "                for col_idx in range(self.nodes.shape[1]):\n",
    "                    theta = self.theta(\n",
    "                        best_match, \n",
    "                        np.array([row_idx, col_idx]), \n",
    "                        step, max_steps)\n",
    "                    alpha = self.alpha(step, max_steps)\n",
    "                    delta = X - self.nodes[row_idx, col_idx]\n",
    "                    self.nodes[row_idx, col_idx] += theta * delta * alpha\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def get_best_matching_index(self, X):\n",
    "        \"\"\"\n",
    "        Calculates the best matching node for data sample X.\n",
    "        Depending on the method used (see __init__), a different\n",
    "        approach is used.\n",
    "        \n",
    "        method 'distance': \n",
    "            Finds the best matching node by minimal distance:\n",
    "                argmin(||n-x||)\n",
    "        other method ('activation'): \n",
    "            Finds the best matching node by maximal excitation:\n",
    "                argmax(nx)\n",
    "        \n",
    "        Args:\n",
    "            X       The data point.\n",
    "        Returns:\n",
    "            The grid coordinates of the best matching node.\n",
    "        \"\"\"\n",
    "        ### BEGIN SOLUTION\n",
    "        reshaped_nodes = self.nodes.reshape(-1, self.nodes.shape[-1])\n",
    "        if self.method == 'distance':\n",
    "            distances = cdist(X[np.newaxis], reshaped_nodes)\n",
    "            best_matching_1D_index = np.argmin(distances)\n",
    "        elif self.method == 'activation':\n",
    "            activations = np.sum(np.multiply(X[np.newaxis], reshaped_nodes), 1)\n",
    "            best_matching_1D_index = np.argmax(activations)\n",
    "        return np.array(\n",
    "            np.unravel_index(best_matching_1D_index, self.nodes.shape[0:2]))\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Allows to access the nodes via the self-organizing map directly.\n",
    "        \n",
    "        som[4,2] \n",
    "        is thus same as \n",
    "        som.nodes[4,2]\n",
    "        \n",
    "        Args:\n",
    "            key The key (can be a slice or similar).\n",
    "        Returns:\n",
    "            self.nodes[key]\n",
    "        \"\"\"\n",
    "        return self.nodes[key]\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"Plots the map's first three features as an image.\"\"\"\n",
    "        _nodes = self.nodes[:, :, 0:3].copy()\n",
    "        _nodes -= _nodes.min()\n",
    "        _nodes /= _nodes.max()\n",
    "        \n",
    "        plt.imshow(_nodes, interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff0c96",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex2b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Apply the Self-Organizing Map\n",
    "\n",
    "Now apply your self-organizing map on some data.\n",
    "\n",
    "We already generate simple color data for you - you can change it if you like.\n",
    "\n",
    "1. Load `world_data.csv`. We recommend using a `csv.reader` for this, as the first column contains strings: the labels you need to use to accomplish the mapping.\n",
    "\n",
    "1. The data has some invalid values (np.nan). Use the `SimpleImputer` (check the imports) to fill them.\n",
    "\n",
    "1. Additionally the data has to be scaled. Use `scale` (check the imports) for this.\n",
    "\n",
    "1. Create two instances of the `SelfOrganizingMap` and organize them, one for the colors and one for the countries. Take care that both have the same sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29a0ea",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex2b_sol",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Generate color data.\n",
    "colors = np.array(list(itertools.product([0, 1], repeat=3)))\n",
    "\n",
    "# TODO: Read world data.\n",
    "### BEGIN SOLUTION\n",
    "with open('world_data.csv', 'r') as in_file:\n",
    "    input_data = list(csv.reader(in_file))[1:]\n",
    "countries = np.array([[d[0], d[1]] for d in input_data], dtype='str_')\n",
    "country_data = np.array([d[2:] for d in input_data], dtype='float_')\n",
    "country_data = scale(SimpleImputer().fit_transform(country_data), axis=0)\n",
    "\n",
    "map_size = (20, 20)\n",
    "max_steps = 400\n",
    "### END SOLUTION\n",
    "\n",
    "# TODO: Create color map and organize it.\n",
    "# som_colors = ...\n",
    "### BEGIN SOLUTION\n",
    "som_colors = SelfOrganizingMap(colors, map_size)\n",
    "som_colors.organize(max_steps)\n",
    "print('Organized colors by distance.')\n",
    "\n",
    "som_colors_act = SelfOrganizingMap(colors, map_size, method='activation')\n",
    "som_colors_act.organize(max_steps)\n",
    "print('Organized colors by activation.')\n",
    "### END SOLUTION\n",
    "\n",
    "# TODO: Create country map and organize it.\n",
    "# som_countries = ...\n",
    "### BEGIN SOLUTION\n",
    "som_countries = SelfOrganizingMap(country_data, map_size)\n",
    "som_countries.organize(max_steps)\n",
    "print('Organized countries by distance.')\n",
    "\n",
    "som_countries_act = SelfOrganizingMap(\n",
    "    country_data, map_size, method='activation')\n",
    "som_countries_act.organize(max_steps)\n",
    "print('Organized countries by activation.')\n",
    "### END SOLUTION\n",
    "\n",
    "# Take a look at the results.\n",
    "plt.figure('SOM')\n",
    "plt.subplot(221).set_title('Colors by Distance')\n",
    "som_colors.plot()\n",
    "plt.subplot(222).set_title('Countries by Distance')\n",
    "som_countries.plot()\n",
    "plt.subplot(223).set_title('Colors by Activation')\n",
    "som_colors_act.plot()\n",
    "plt.subplot(224).set_title('Countries by Activation')\n",
    "som_countries_act.plot()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a56b16",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex2c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Select the best matching indices for each country from the country map. Use those indices to select the corresponding color from the color map. Create the mapping from ISO codes to colors and use the `create_colored_map` function to produce the colored SVG map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0960a",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex2c_sol",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Match countries to colors.\n",
    "### BEGIN SOLUTION\n",
    "mapping = {}\n",
    "for i, country_d in enumerate(country_data):\n",
    "    x, y = som_countries.get_best_matching_index(country_d)\n",
    "    mapping[countries[i,1]] = som_colors[x,y]\n",
    "### END SOLUTION\n",
    "\n",
    "# TODO: Create colored map.\n",
    "### BEGIN SOLUTION\n",
    "create_colored_map(mapping)\n",
    "\n",
    "# TODO: Match countries to colors.\n",
    "mapping_act = {}\n",
    "for i, country_d in enumerate(country_data):\n",
    "    x, y = som_countries_act.get_best_matching_index(country_d)\n",
    "    mapping_act[countries[i,1]] = som_colors_act[x,y]\n",
    "\n",
    "# TODO: Create colored map.\n",
    "create_colored_map(mapping_act)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f9c70a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex4_h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 4: Bayes classifier (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ba5ea",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex4_h01",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Consider the following data set. There are four features, running nose ($N$), coughing ($C$), reddened skin ($R$), and fever ($F$), each of which can take the values true ($+$) or false ($-$).\n",
    "\n",
    "| Diagnosis ID  | $N$ | $C$ | $R$ | $F$ | Classification     |\n",
    "|---------------|-----|-----|-----|-----|--------------------|\n",
    "|     $d_1$     | $+$ | $+$ | $+$ | $-$ | positive (ill)     |\n",
    "|     $d_2$     | $+$ | $+$ | $-$ | $-$ | positive (ill)     |\n",
    "|     $d_3$     | $-$ | $-$ | $+$ | $+$ | positive (ill)     |\n",
    "|     $d_4$     | $+$ | $-$ | $-$ | $-$ | negative (healthy) |\n",
    "|     $d_5$     | $-$ | $-$ | $-$ | $-$ | negative (healthy) |\n",
    "|     $d_6$     | $-$ | $+$ | $+$ | $-$ | negative (healthy) |\n",
    "\n",
    "Solve the following problems either by hand or programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9231f6e5",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex4_a00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Determine all probabilities required to apply a naive Bayes classifier for predicting whether a new person is ill or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa41b24",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex4_a_sol",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The unconditional probability of being ill and healthy according to this dataset is\n",
    "\n",
    "$$P(ill) = \\frac{3}{6}= \\frac{1}{2}\\qquad P(healthy) =\\frac{3}{6}= \\frac{1}{2}$$\n",
    "\n",
    "For the features N, C, R, the number of positive and negative examples for ill and healthy patients are identical. Hence the conditional probabilities will be the same, so we will use $x$ to denote any of these three features:\n",
    "\\begin{align*}\n",
    "P(x_\\oplus)   &= \\frac{1}{2} & P(x_\\ominus)   &= \\frac{1}{2} \\\\\n",
    "P(x_\\oplus\\,|\\,ill) &= \\frac{2}{3} & p(x_\\ominus\\,|\\,ill) &= \\frac{1}{3} \\\\\n",
    "P(x_\\oplus\\,|\\,healthy) &= \\frac{1}{3} & P(x_\\ominus\\,|\\,healthy) &= \\frac{2}{3} \\\\\n",
    "\\end{align*}\n",
    "For $F$ the situation is different, leading to the following probabilities:\n",
    "\\begin{align*}\n",
    "P(F_\\oplus)   &= \\frac{1}{6} & P(F_\\ominus)   &= \\frac{5}{6} \\\\\n",
    "P(F_\\oplus\\,|\\,ill) &= \\frac{1}{3} & P(F_\\ominus\\,|\\,ill) &= \\frac{2}{3} \\\\\n",
    "P(F_\\oplus\\,|\\,healthy) &= 0   & P(F_\\ominus\\,|\\,healthy) &= 1   \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc41ce56",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex4_b00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** Person $p_1$ is coughing and has fever. Person $p_2$ has a running nose and reddened skin. Person $p_3$ is coughing, suffers from reddened skin and has fever. Use the naive Bayes classifier to determine the probability of being ill for all persons $p1, p2, p3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64545084",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex4_b_sol",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Using an [alternative form of the Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem#Alternative_form):\n",
    "$$P(A\\,|\\,B) = \\frac{P(B\\,|\\,A) \\cdot P(A)}{(P(B\\,|\\,A) \\cdot P(A)) + P(B\\,|\\,\\neg A) \\cdot P(\\neg A)}$$\n",
    "\n",
    "$$\\begin{align*}\n",
    "P_{p_1}(ill\\,|\\,N_\\ominus, C_\\oplus, R_\\ominus, F_\\oplus) \n",
    "&= \n",
    "\\frac{\n",
    "  \\frac{1}{3}\\frac{2}{3}\\frac{1}{3}\\frac{1}{3}  \\cdot \\frac{1}{2}\n",
    "}{\n",
    "  \\frac{1}{3}\\frac{2}{3}\\frac{1}{3}\\frac{1}{3} \\cdot \\frac{1}{2} + \n",
    "  \\frac{1}{3}\\frac{2}{3}\\frac{1}{3}0 \\cdot \\frac{1}{2}\n",
    "}\n",
    "= \\frac{\\frac{2}{81}\\frac{1}{2}}{\\frac{1}{81}+0} \n",
    "= 1\n",
    "\\\\\n",
    "P_{p_2}(ill\\,|\\,N_\\oplus, C_\\ominus, R_\\oplus, F_\\ominus) \n",
    "&= \n",
    "\\frac{\n",
    "  \\frac{2}{3}\\frac{1}{3}\\frac{2}{3}\\frac{2}{3} \\cdot \\frac{1}{2}\n",
    "}{\n",
    "  \\frac{2}{3}\\frac{1}{3}\\frac{2}{3}\\frac{2}{3} \\cdot \\frac{1}{2} + \n",
    "  \\frac{1}{3}\\frac{2}{3}\\frac{1}{3}1 \\cdot \\frac{1}{2}\n",
    "}\n",
    "= \\frac{\\frac{8}{81}\\frac{1}{2}}{\\frac{4}{81}+\\frac{1}{27}} \n",
    "= \\frac{4}{7} \n",
    "\\\\\n",
    "P_{p_3}(ill\\,|\\,N_\\ominus, C_\\oplus, R_\\oplus, F_\\oplus) \n",
    "&= \n",
    "\\frac{\n",
    "  \\frac{1}{3}\\frac{2}{3}\\frac{2}{3}\\frac{1}{3} \\cdot \\frac{1}{2}\n",
    "}{\n",
    "  \\frac{1}{3}\\frac{2}{3}\\frac{2}{3}\\frac{1}{3} \\cdot \\frac{1}{2} + \n",
    "  \\frac{2}{3}\\frac{1}{3}\\frac{1}{3}0 \\cdot \\frac{1}{2}\n",
    "}\n",
    "= \\frac{\\frac{4}{81}\\frac{1}{2}}{\\frac{2}{81}+0} \n",
    "= 1\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf9285",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ex-bayes-c-q",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**c)** What does naivity in the context of Bayes classifier mean. How would the computations change if you drop naivity? What would be the probabilities for persons $p1, p2, p3$ being ill in a non-naive setting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6af7e",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex-bayes-c-a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
